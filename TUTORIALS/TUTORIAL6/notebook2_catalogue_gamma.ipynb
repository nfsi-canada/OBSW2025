{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af8420a-6ded-4ae9-a2b6-caf5bff57d51",
   "metadata": {},
   "source": [
    "## Tutorial 7: Building an earthquake catalogue using GaMMA\n",
    "\n",
    "In this demonstration we will show how to automatically build an earthquake catalogue using SeisBench and the GaMMA associator with OBS data to create an earthquake catalog from raw waveforms. We will use example data from the [YH](https://ds.iris.edu/gmap/#network=YH&starttime=2014-01-01&endtime=2015-06-01&planet=earth) network from the HOBITSS deployment in 2014-2015.\n",
    "\n",
    "First, we import the seisbench and gamma packages, as well as other required packages and modules to import data and make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0159f-141d-4d24-8751-84fe3e471592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeisBench models\n",
    "import seisbench.models as sbm\n",
    "\n",
    "# GaMMA associator\n",
    "from gamma.utils import association\n",
    "\n",
    "# ObsPy classes\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime, Stream\n",
    "\n",
    "# Other ancillary packages\n",
    "from pyproj import CRS, Transformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29223382-f096-45c1-80cd-4c3e3632c51d",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "The following code cells contain all configurations. The first cell configures the local coordinate projection. In this case, we use a transverse mercator projection for New Zealand, as we will be using data from northern New Zealand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debeaf19-5320-4bad-ad9a-f96e8c0bc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projections - Hard coded for YH and North Island grid\n",
    "wgs84 = CRS.from_epsg(4326)\n",
    "local_crs = CRS.from_epsg(27291)  # NZGD49 / North Island Grid: https://epsg.io/27291#google_vignette\n",
    "transformer = Transformer.from_crs(wgs84, local_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff417d5-789f-4844-b391-19415fa3063f",
   "metadata": {},
   "source": [
    "The second, third and fourth cells configure the gamma associator. Please see it's documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d4ad2-e2ab-42a0-bdb6-8419b837cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma\n",
    "config = {}\n",
    "config[\"dims\"] = ['x(km)', 'y(km)', 'z(km)']\n",
    "\n",
    "# Use dbscan to cut a long sequence of picks into segments to speed up associaiton using small windows.\n",
    "config[\"use_dbscan\"] = True\n",
    "config[\"use_amplitude\"] = False\n",
    "\n",
    "# Extent of box to investigate - events occurring outside this box will localize to the edges\n",
    "# Check with extent of stations to adjust these numbers\n",
    "config[\"x(km)\"] = (100, 600)\n",
    "config[\"y(km)\"] = (250, 500)\n",
    "config[\"z(km)\"] = (0, 150)\n",
    "\n",
    "# Average crustal P- and S-wave velocities\n",
    "config[\"vel\"] = {\"p\": 5.0, \"s\": 5.0 / 1.75}  \n",
    "config[\"method\"] = \"BGMM\"\n",
    "if config[\"method\"] == \"BGMM\":\n",
    "    config[\"oversample_factor\"] = 4\n",
    "if config[\"method\"] == \"GMM\":\n",
    "    config[\"oversample_factor\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee831a-72e2-4122-8906-1b8c686a59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "config[\"bfgs_bounds\"] = (\n",
    "    (config[\"x(km)\"][0] - 1, config[\"x(km)\"][1] + 1),  # x\n",
    "    (config[\"y(km)\"][0] - 1, config[\"y(km)\"][1] + 1),  # y\n",
    "    (0, config[\"z(km)\"][1] + 1),  # x\n",
    "    (None, None),  # t\n",
    ")\n",
    "\n",
    "# The maximum time between two picks for one to be considered as a neighbor of the other. See details in DBSCAN\n",
    "config[\"dbscan_eps\"] = 25  # seconds\n",
    "\n",
    "# The number of samples in a neighborhood for a point to be considered as a core point. See details in DBSCAN\n",
    "config[\"dbscan_min_samples\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f70bb-9efa-4067-aebf-b75ff4f68ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "# Minimum picks per earthquake\n",
    "config[\"min_picks_per_eq\"] = 5\n",
    "\n",
    "# Max phase time residual (s)\n",
    "config[\"max_sigma11\"] = 2.0\n",
    "\n",
    "# Max phase amplitude residual (in log scale)\n",
    "config[\"max_sigma22\"] = 1.0\n",
    "\n",
    "# Max covariance term. (Usually not used)\n",
    "config[\"max_sigma12\"] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710ced0-cedb-4cc6-b905-5907073f7b16",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "We download waveform data for 60 minutes from the YH network offshore northern New Zealand (HOBITSS deployment). We use October 2, 2014, which corresponds to a magnitude [4.6 earthquake](https://www.geonet.org.nz/earthquake/technical/2014p742742) in the vicinity of the HOBITSS deployment. Therefore, we expect to detect low-magnitude aftershocks in this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06864d-d26b-42c6-972a-12f413ce9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FDSN client\n",
    "client = Client()\n",
    "\n",
    "# Start time in UTC at the mainshock\n",
    "t0 = UTCDateTime(\"2014-10-02T19:33:00\")\n",
    "\n",
    "# End time, 60 minutes later\n",
    "t1 = t0 + 60 * 60\n",
    "\n",
    "# Get waveform data\n",
    "stream = client.get_waveforms(network=\"YH\", station=\"*\", location=\"*\", channel=\"?H?\", starttime=t0, endtime=t1)\n",
    "\n",
    "# Get station metadata\n",
    "inv = client.get_stations(network=\"YH\", station=\"*\", location=\"*\", channel=\"?H?\", starttime=t0, endtime=t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38715e4-9b99-440e-a695-e3959a731cc0",
   "metadata": {},
   "source": [
    "### Annotate waveforms\n",
    "\n",
    "For this example, we use OBSTransformer model. However, in principle any picker could be used for obtaining the picks with only minimal changes. \n",
    "\n",
    "> Warning: This will take some time and requires sufficient main memory. If you are short on memory, reduce the study time in the cell before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b1c96-5aed-4565-b745-cdc295c2680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained OBSTransformer model weights\n",
    "#picker = sbm.OBSTransformer.from_pretrained('obst2024')\n",
    "picker = sbm.PickBlue()\n",
    "\n",
    "# We tuned the thresholds a bit - Feel free to play around with these values\n",
    "picks = picker.classify(stream, batch_size=256, P_threshold=0.075, S_threshold=0.1).picks\n",
    "\n",
    "# Output number of P and S picks\n",
    "Counter([p.phase for p in picks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf3a0b-b0ed-4535-9377-3342195e631e",
   "metadata": {},
   "source": [
    "We now convert the picks into pandas dataframes in the format required for the GaMMA associator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95842788-d9f4-4bc2-9dd9-ccec0e72fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list and fill it with pick info\n",
    "pick_df = []\n",
    "for p in picks:\n",
    "    pick_df.append({\n",
    "        \"id\": p.trace_id,\n",
    "        \"timestamp\": p.peak_time.datetime,\n",
    "        \"prob\": p.peak_value,\n",
    "        \"type\": p.phase.lower()\n",
    "    })\n",
    "\n",
    "# Store it into a DataFrame\n",
    "pick_df = pd.DataFrame(pick_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff0227-f1ff-42ca-81ae-78ae915b3e96",
   "metadata": {},
   "source": [
    "Let's have a look at the picks generated by the model. Note that we retained the probabilities from the deep learning model. It will be used by the associator later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf27ef2-8d31-4632-bca8-015933216b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_df.sort_values(\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af08a36-7409-4088-8665-13bf7cd9c1f8",
   "metadata": {},
   "source": [
    "Convert station metadata into pandas dataframe in the format required for the GaMMA associator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccea7b-3eb3-4c0e-a634-16beffc96a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list and fill it with station info\n",
    "station_df = []\n",
    "for station in inv[0]:\n",
    "    station_df.append({\n",
    "        \"id\": f\"YH.{station.code}.\",\n",
    "        \"longitude\": station.longitude,\n",
    "        \"latitude\": station.latitude,\n",
    "        \"elevation(m)\": station.elevation\n",
    "    })\n",
    "\n",
    "# Store it as a DataFrame\n",
    "station_df = pd.DataFrame(station_df)\n",
    "\n",
    "# Convert map coordinates to km\n",
    "station_df[\"x(km)\"] = station_df.apply(lambda x: transformer.transform(x[\"latitude\"], x[\"longitude\"])[0] / 1e3, axis=1)\n",
    "station_df[\"y(km)\"] = station_df.apply(lambda x: transformer.transform(x[\"latitude\"], x[\"longitude\"])[1] / 1e3, axis=1)\n",
    "station_df[\"z(km)\"] = - station_df[\"elevation(m)\"] / 1e3\n",
    "\n",
    "# Create station dictionary for easier handling of later plots\n",
    "station_dict = {station: (x, y) for station, x, y in zip(station_df[\"id\"], station_df[\"x(km)\"], station_df[\"y(km)\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a004d0-58ba-4c78-abb7-d9719b42ada6",
   "metadata": {},
   "source": [
    "Inspect the station dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed69d9c-0923-4f18-939c-1f7deff47048",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba8606-7336-404b-b6c0-4b2fe57e13de",
   "metadata": {},
   "source": [
    "### GaMMA association\n",
    "\n",
    "We now run the phase association. This will take a moment. We convert the output into two dataframes, one for the catalogue and one for the assignment of picks to the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2f05e-1faa-4514-9485-f254062ee3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the associator\n",
    "catalogs, assignments = association(pick_df, station_df, config, method=config[\"method\"])\n",
    "\n",
    "# Store the catalog and assignments into a dataframe\n",
    "catalog = pd.DataFrame(catalogs)\n",
    "assignments = pd.DataFrame(assignments, columns=[\"pick_idx\", \"event_idx\", \"prob_gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a35d4-1bfe-4e1a-9080-2b980165221d",
   "metadata": {},
   "source": [
    "Make a plot of catalog and stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35fe62b-8944-4ee3-a2c7-d54867fe3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Show catalog events in km coordinates\n",
    "cb = ax.scatter(catalog[\"x(km)\"], catalog[\"y(km)\"], c=catalog[\"z(km)\"], s=8, cmap=\"viridis\")\n",
    "\n",
    "# Add color bar for focal depth\n",
    "cbar = fig.colorbar(cb)\n",
    "cbar.ax.set_ylim(cbar.ax.get_ylim()[::-1])\n",
    "cbar.set_label(\"Depth[km]\")\n",
    "\n",
    "# Add stations\n",
    "ax.plot(station_df[\"x(km)\"], station_df[\"y(km)\"], \"r^\", ms=10, mew=1, mec=\"k\")\n",
    "ax.set_xlabel(\"Easting [km]\")\n",
    "ax.set_ylabel(\"Northing [km]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c3a78-0403-4cfa-ac20-d7ca39c985f3",
   "metadata": {},
   "source": [
    "Make a plot of traces and picks for a random earthquake in the catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8de1e5-7b1d-4786-8c57-cd4b3a730ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random event in catalog\n",
    "# event_idx = np.random.choice(catalog[\"event_index\"])\n",
    "# event_idx = catalog[\"event_index\"][5]\n",
    "for event_idx in catalog[\"event_index\"]:\n",
    "\n",
    "    # Extract picks and event info for this event\n",
    "    event_picks = [picks[i] for i in assignments[assignments[\"event_idx\"] == event_idx][\"pick_idx\"]]\n",
    "    event = catalog[catalog[\"event_index\"] == event_idx].iloc[0]\n",
    "    \n",
    "    # Extract window to include min and max pick times according to all picks\n",
    "    first, last = min(pick.peak_time for pick in event_picks), max(pick.peak_time for pick in event_picks)\n",
    "    \n",
    "    # Initialize empty stream\n",
    "    sub = Stream()\n",
    "    \n",
    "    # Add streams for stations that contain a pick - here we extract the \"Z\" component\n",
    "    for station in np.unique([pick.trace_id for pick in event_picks]):\n",
    "        sub.append(stream.select(station=station[3:-1], channel=\"?HZ\")[0])\n",
    "    \n",
    "    # Extend window by +/- 5 seconds\n",
    "    sub = sub.slice(first - 5, last + 5)\n",
    "    \n",
    "    # Pre-process the data: detrend and high-pass filter at 1 Hz\n",
    "    sub = sub.copy()\n",
    "    sub.detrend()\n",
    "    sub.filter(\"highpass\", freq=2)\n",
    "    \n",
    "    # Initialize figure\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Plot the seismograms, ordered by total distance (hypocentral) from earthquake\n",
    "    for i, trace in enumerate(sub):\n",
    "        # Remove mean\n",
    "        normed = trace.data - np.mean(trace.data)\n",
    "        # Divide by max of absolute value\n",
    "        normed = normed / np.max(np.abs(normed))\n",
    "        # Extract x and y position of station\n",
    "        station_x, station_y = station_dict[trace.id[:-4]]\n",
    "        # Calculate euclidian hypocentral distance\n",
    "        y = np.sqrt((station_x - event[\"x(km)\"]) ** 2 + (station_y - event[\"y(km)\"]) ** 2 + event[\"z(km)\"] ** 2)\n",
    "        # Plot trace at corresponding distance\n",
    "        ax.plot(trace.times(), 3 * normed + y)\n",
    "    \n",
    "    # Plot the picks as vertical bars lined up on each seismogram\n",
    "    for pick in event_picks:\n",
    "        # Extract x and y position of station\n",
    "        station_x, station_y = station_dict[pick.trace_id]\n",
    "        # # Calculate euclidian hypocentral distance\n",
    "        y = np.sqrt((station_x - event[\"x(km)\"]) ** 2 + (station_y - event[\"y(km)\"]) ** 2 + event[\"z(km)\"] ** 2)\n",
    "        # Calculate arrival time wrt window time\n",
    "        x = pick.peak_time - trace.stats.starttime\n",
    "        if pick.phase == \"P\":\n",
    "            ls = '-'\n",
    "        else:\n",
    "            ls = '--'\n",
    "        # Plot as vertical bars\n",
    "        ax.plot([x, x], [y - 3, y + 3], 'k', ls=ls)\n",
    "        \n",
    "    # ax.set_ylim(0)\n",
    "    ax.set_xlim(0, np.max(trace.times()))\n",
    "    ax.set_ylabel(\"Hypocentral distance [km]\")\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    \n",
    "    # Print out event information\n",
    "    print(\"Event information\")\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
